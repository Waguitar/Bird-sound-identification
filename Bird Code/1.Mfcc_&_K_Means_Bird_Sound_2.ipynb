{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#General\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# System\n",
    "import os, fnmatch\n",
    "\n",
    "# Visualization\n",
    "import seaborn #visualization library, must be imported before all other plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "# Random Seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# Audio\n",
    "import librosa.display, librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 25 audio files in TestSound2/\n"
     ]
    }
   ],
   "source": [
    "# Get files in data path\n",
    "path='TestSound2/'\n",
    "# Get Audio Files\n",
    "files = []\n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "        files.append(os.path.join(root, filename))\n",
    "\n",
    "print(\"found %d audio files in %s\"%(len(files),path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare labels from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =[]\n",
    "classes=['Test']\n",
    "\n",
    "\n",
    "\n",
    "color_dict={'Test':'blue'}\n",
    "\n",
    "color_list=[]\n",
    "for filename in files:\n",
    "    for name in classes:\n",
    "        if fnmatch.fnmatchcase(filename, '*'+name+'*'):\n",
    "            labels.append(name)\n",
    "            color_list.append(color_dict[name])\n",
    "            break\n",
    "    else:\n",
    "        labels.append('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 classes: Test\n"
     ]
    }
   ],
   "source": [
    "# Encode Labels\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(labels)\n",
    "print(len(labelencoder.classes_), \"classes:\", \", \".join(list(labelencoder.classes_)))\n",
    "classes_num = labelencoder.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Signal Processing Parameters\n",
    "fs = 44100         # Sampling Frequency\n",
    "n_fft = 2048       # length of the FFT window\n",
    "hop_length = 512   # Number of samples between successive frames\n",
    "n_mels = 128       # Number of Mel bands\n",
    "n_mfcc = 13        # Number of MFCCs\n",
    "\n",
    "# Machine Learning Parameters\n",
    "testset_size = 0.25 #Percentage of data for Testing\n",
    "n_neighbors=1       # Number of neighbors for kNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Calculate Audio Features: MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to Calculate MFCC, Delta_MFCC and Delta2_MFCC\n",
    "def get_features(y, sr=fs):\n",
    "    S = librosa.feature.melspectrogram(y, sr=fs, n_mels=n_mels)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=n_mfcc)\n",
    "    feature_vector = np.mean(mfcc,1)\n",
    "    #feature_vector = (feature_vector-np.mean(feature_vector))/np.std(feature_vector)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load audio files, calculate features and create feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 1 of 25 = TestSound2/XC141694 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 2 of 25 = TestSound2/XC2479 - Andean Avocet - Recurvirostra andina.wav\n",
      "get 3 of 25 = TestSound2/XC333699 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 4 of 25 = TestSound2/XC199264 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 5 of 25 = TestSound2/XC133080 - American Avocet - Recurvirostra americana.wav\n",
      "get 6 of 25 = TestSound2/XC188266 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 7 of 25 = TestSound2/XC325032 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 8 of 25 = TestSound2/XC313293 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 9 of 25 = TestSound2/XC325032 - Pied Avocet - Recurvirostra avosetta (1).wav\n",
      "get 10 of 25 = TestSound2/XC304644 - American Avocet - Recurvirostra americana.wav\n",
      "get 11 of 25 = TestSound2/XC2474 - Andean Avocet - Recurvirostra andina.wav\n",
      "get 12 of 25 = TestSound2/XC281050 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 13 of 25 = TestSound2/XC145135 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 14 of 25 = TestSound2/XC202859 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 15 of 25 = TestSound2/XC146958 - Andean Avocet - Recurvirostra andina.wav\n",
      "get 16 of 25 = TestSound2/XC202858 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 17 of 25 = TestSound2/XC290087 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 18 of 25 = TestSound2/XC317972 - American Avocet - Recurvirostra americana.wav\n",
      "get 19 of 25 = TestSound2/XC149144 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 20 of 25 = TestSound2/XC59841 - Andean Avocet - Recurvirostra andina.wav\n",
      "get 21 of 25 = TestSound2/XC318019 - American Avocet - Recurvirostra americana.wav\n",
      "get 22 of 25 = TestSound2/XC178760 - American Avocet - Recurvirostra americana.wav\n",
      "get 23 of 25 = TestSound2/XC281049 - Pied Avocet - Recurvirostra avosetta.wav\n",
      "get 24 of 25 = TestSound2/XC95529 - Andean Avocet - Recurvirostra andina.wav\n",
      "get 25 of 25 = TestSound2/XC12130 - American Avocet - Recurvirostra americana.wav\n",
      "Calculated 25 feature vectors\n"
     ]
    }
   ],
   "source": [
    "# Load audio files, calculate features and create feature vectors\n",
    "feature_vectors = []\n",
    "sound_paths = []\n",
    "for i,f in enumerate(files):\n",
    "    print (\"get %d of %d = %s\"%(i+1, len(files), f))\n",
    "    try:\n",
    "        y, sr = librosa.load(f, sr=fs)\n",
    "        y/=y.max() #Normalize\n",
    "        if len(y) < 2:\n",
    "            print(\"Error loading %s\" % f)\n",
    "            continue\n",
    "        feat = get_features(y, sr)\n",
    "        feature_vectors.append(feat)\n",
    "        sound_paths.append(f)\n",
    "    except Exception as e:\n",
    "        print(\"Error loading %s. Error: %s\" % (f,e))\n",
    "        \n",
    "print(\"Calculated %d feature vectors\"%len(feature_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization: Zero-Mean and Unit-Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors shape: (25, 13)\n"
     ]
    }
   ],
   "source": [
    "# Scale features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_feature_vectors = scaler.fit_transform(np.array(feature_vectors))\n",
    "print(\"Feature vectors shape:\",scaled_feature_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Set\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0)\n",
    "splits = splitter.split(scaled_feature_vectors, classes_num)\n",
    "for train_index, test_index in splits:\n",
    "    train_set = scaled_feature_vectors[train_index]\n",
    "    test_set = scaled_feature_vectors[test_index]\n",
    "    train_classes = classes_num[train_index]\n",
    "    test_classes = classes_num[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape: (18, 13)\n",
      "test_set shape: (7, 13)\n",
      "train_classes shape: (18,)\n",
      "test_classes shape: (7,)\n"
     ]
    }
   ],
   "source": [
    "# Check Set Shapes\n",
    "print(\"train_set shape:\",train_set.shape)\n",
    "print(\"test_set shape:\",test_set.shape)\n",
    "print(\"train_classes shape:\",train_classes.shape)\n",
    "print(\"test_classes shape:\",test_classes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans = sklearn.cluster.KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.fit(train_set, train_classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 1 1 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict using the Test Set\n",
    "predicted_labels = model_kmeans.predict(test_set)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, other clustering algorithms such as affinity propagation can cluster without defining the number of clusters beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_affinity = sklearn.cluster.AffinityPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_affinity.fit(train_set, train_classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 1 1 4 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Predict using the Test Set\n",
    "predicted_labels = model_affinity.predict(test_set)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
